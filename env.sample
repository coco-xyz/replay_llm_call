# replay-llm-call - Environment Configuration
# Copy this file to .env and update the values as needed
#
# This template provides a foundation for building AI agent applications.
# Configure only the settings you need for your specific use case.
#
# All configuration fields correspond exactly to replay_llm_call/core/config.py

# =============================================================================
# Application Settings
# =============================================================================

# Enable debug mode for development (default: false)
# Set to true for detailed logging and auto-reload
DEBUG=false

# Logging level (default: info)
# Options: debug, info, warning, error
LOG_LEVEL=info

# Application environment (default: development)
# Options: development, staging, production
ENVIRONMENT=development

# =============================================================================
# API Configuration
# =============================================================================

# API server settings
API__TITLE=replay-llm-call
API__DESCRIPTION=AI Agent Application
API__VERSION=1.0.0
API__DOCS_URL=/docs
API__REDOC_URL=/redoc

# CORS settings for web applications
CORS__ALLOW_ORIGINS=*
CORS__ALLOW_CREDENTIALS=false
CORS__ALLOW_METHODS=GET,POST,PUT,DELETE
CORS__ALLOW_HEADERS=*

# =============================================================================
# AI Model Configuration
# =============================================================================

# API Keys - Add the ones you plan to use
# Get OpenAI API key from: https://platform.openai.com/api-keys
AI__OPENAI_API_KEY=your-openai-api-key-here

# Get Anthropic API key from: https://console.anthropic.com/
AI__ANTHROPIC_API_KEY=your-anthropic-api-key-here

# Get Google API key from: https://aistudio.google.com/app/apikey
AI__GOOGLE_API_KEY=your-google-api-key-here

# Get OpenRouter API key from: https://openrouter.ai/keys
AI__OPENROUTER_API_KEY=your-openrouter-api-key-here

# Default model configuration
AI__DEFAULT_MODEL__PROVIDER=openrouter
AI__DEFAULT_MODEL__NAME=openai/gpt-4o-mini

# Demo agent model configuration
AI__DEMO_AGENT__PROVIDER=openrouter
AI__DEMO_AGENT__MODEL_NAME=openai/gpt-4o-mini

# Additional business-specific agent configurations (optional)
# AI__CHAT_AGENT__PROVIDER=anthropic
# AI__CHAT_AGENT__MODEL_NAME=claude-3-5-sonnet-20241022
# AI__ANALYSIS_AGENT__PROVIDER=google
# AI__ANALYSIS_AGENT__MODEL_NAME=gemini-1.5-pro

# Fallback model configuration (used when primary models fail)
AI__FALLBACK__PROVIDER=openai
AI__FALLBACK__MODEL_NAME=gpt-4o-mini

# =============================================================================
# Database Configuration (Optional)
# =============================================================================

# Database connection URL (default: postgresql://user:password@localhost:5432/agent_db)
# For SQLite (simple, no setup required):
# DATABASE__URL=sqlite:///./replay_llm_call.db
# For PostgreSQL (production recommended):
DATABASE__URL=postgresql://user:password@localhost:5432/agent_db
# For Docker PostgreSQL:
# DATABASE__URL=postgresql://username:password@postgres:5432/agent_db

# Database settings
DATABASE__ECHO=false
DATABASE__POOL_SIZE=10
DATABASE__MAX_OVERFLOW=20
DATABASE__POOL_TIMEOUT=30
DATABASE__POOL_RECYCLE=3600
DATABASE__POOL_PRE_PING=true

# =============================================================================
# Redis Configuration (Optional - for caching and sessions)
# =============================================================================

# Redis connection settings
REDIS__HOST=localhost
REDIS__PORT=6379
REDIS__DB=0
# REDIS__PASSWORD=your-redis-password-here
REDIS__SSL=false
REDIS__CONNECT_TIMEOUT=3.0
REDIS__SOCKET_TIMEOUT=3.0

# Redis lock configuration
REDIS_LOCK__RETRY_SLEEP_INTERVAL=0.1

# =============================================================================
# Logging File Configuration (Optional)
# =============================================================================

# Directory to store log files (default: logs)
LOG__DIR=logs

# Custom log file path (overrides LOG__DIR if set)
# LOG__FILE_PATH=/var/log/replay_llm_call/app.log

# File handler log level (default: INFO)
# Options: DEBUG, INFO, WARNING, ERROR
LOG__FILE_LEVEL=INFO

# Log file max size in bytes before rotation (default: 10MB)
LOG__FILE_MAX_BYTES=10485760

# Number of rotated files to keep (default: 3)
LOG__FILE_BACKUP_COUNT=3

# =============================================================================
# Monitoring Configuration (Optional)
# =============================================================================

# Logfire monitoring (https://logfire.pydantic.dev/)
LOGFIRE__ENABLED=false
LOGFIRE__SERVICE_NAME=replay_llm_call
LOGFIRE__ENVIRONMENT=development
LOGFIRE__TOKEN=your-logfire-token-here
LOGFIRE__DISABLE_SCRUBBING=false

# Logfire instrumentation toggles
LOGFIRE__INSTRUMENT__PYDANTIC_AI=true
LOGFIRE__INSTRUMENT__REDIS=true
LOGFIRE__INSTRUMENT__HTTPX=true
LOGFIRE__INSTRUMENT__FASTAPI=true
LOGFIRE__HTTPX_CAPTURE_ALL=false

# =============================================================================
# File Upload Configuration (Optional)
# =============================================================================

# Maximum file upload size in bytes (10MB default)
UPLOAD_MAX_SIZE=10485760

# Allowed file extensions (comma-separated)
UPLOAD_ALLOWED_EXTENSIONS=.txt,.md,.json

# =============================================================================
# Quick Setup Guide
# =============================================================================

# 1. Minimal setup (CLI mode only):
#    - Set AI__OPENAI_API_KEY (or your preferred AI provider)
#    - Run: python main.py --mode cli

# 2. API mode setup:
#    - Set AI__OPENAI_API_KEY
#    - Run: python main.py --mode api
#    - Visit: http://localhost:8080/docs

# 3. Full setup with database:
#    - Set AI__OPENAI_API_KEY
#    - Set DATABASE__URL (PostgreSQL recommended)
#    - Run: python main.py --mode api

# 4. Production setup:
#    - Set all required AI keys
#    - Use PostgreSQL for DATABASE__URL
#    - Set ENVIRONMENT=production
#    - Set DEBUG=false
#    - Configure LOGFIRE__ENABLED=true for monitoring

# =============================================================================
# Environment-Specific Examples
# =============================================================================

# Development (local):
# DEBUG=true
# ENVIRONMENT=development
# DATABASE__URL=sqlite:///./replay_llm_call.db
# REDIS__HOST=localhost
# REDIS__PORT=6379

# Docker Compose:
# ENVIRONMENT=development
# DATABASE__URL=postgresql://username:password@postgres:5432/agent_db
# REDIS__HOST=redis
# REDIS__PORT=6379

# Production:
# DEBUG=false
# ENVIRONMENT=production
# DATABASE__URL=postgresql://username:password@prod-db-host:5432/agent_db
# LOGFIRE__ENABLED=true
# LOGFIRE__TOKEN=your-production-logfire-token

# =============================================================================
# Notes
# =============================================================================

# All configuration fields in this file correspond exactly to the Settings class
# in replay_llm_call/core/config.py.
#
# Environment variables use double underscores (__) as nested delimiters.
# For example: ai__openai_api_key becomes AI__OPENAI_API_KEY
#
# SecretStr fields (API keys, tokens) are automatically secured in logs.

# ==============================================================================
# For docker-compose.yml
# ==============================================================================
DB_PORT=5432
APP_PORT=8080